# DQN hyperparams following Rainbow. Follows hyperparams from Dopamine:
# github.com/google/dopamine/blob/master/dopamine/agents/dqn/configs/dqn.gin
experiment: M-DQN

env:
  name: Breakout
  args_:
    history_length: 4
    obs_mode: L
    obs_dims: [96, 96]

device: cuda
save: yes
replay_save_freq: 2

epoch_cnt: 50
train_step_cnt: 250_000
valid_step_cnt: 125_000
val_epsilon: 0.001  # validation epsilon greedy

agent:
  name: M-DQN
  args_:
    epsilon: [linear, 1.0, 0.01, 250000, 20_000]
    gamma: 0.99
    loss_fn: MSELoss
    hist_len: 4
    update_freq: 4
    target_update_freq: 8000

replay_:
  capacity: 1_000_000
  hist_len: 1
  batch_size: 32
  device: cpu

estimator:
  encoder:
    name: WMEncoder  # look under ul/nets/
    freeze: yes
    args_:
      # root: results/2023May17-200740_ae/0000_AE_wm--dev/0/
      # root: results/2023May18-173356_tc2/0000_TC2_wm--dev/0/
      root: results/2023May20-084305_AE_b64/0000_AE_wm--dev/0/
      ckpt_idx: 922315
      # ckpt_idx: 1500001
      inp_ch: 4
      with_logvar: no
  qval_net:
    name: CNN
    args_:
      inp_ch: 4  # 2x when with_logvar
      hist_len: 1
      fc_layers: [512]
      cn_layers: [[32, 3, 1], [32, 3, 1]]
      initializer: "xavier_uniform"  # this field can be missing

optim:
  name: "Adam"
  args_:
    lr: 0.0000625
    eps: 0.0001500
